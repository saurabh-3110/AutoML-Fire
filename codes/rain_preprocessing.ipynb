{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined unique coordinates saved to: combined_unique_coordinates.csv\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the folder containing the NetCDF files\n",
    "folder_path = \"dataset-satellite-precipitation-ec9f814a-6a57-440d-9652-1b5fcab3b128\"\n",
    "\n",
    "# Define the target latitude and longitude grids with 0.25 spacing\n",
    "target_lat = np.arange(6.5, 38.5, 0.25)  # Target latitude grid with 0.25 spacing\n",
    "target_lon = np.arange(66.5, 100, 0.25)  # Target longitude grid with 0.25 spacing\n",
    "\n",
    "# Initialize an empty DataFrame to hold the combined data\n",
    "combined_dataframe = pd.DataFrame()\n",
    "\n",
    "# Loop through all NetCDF files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".nc\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Open the original NetCDF file\n",
    "        original_data = xr.open_dataset(file_path)\n",
    "        \n",
    "        # Identify latitude and longitude coordinates or dimensions\n",
    "        lat_name = [dim for dim in original_data.coords if 'latitude' in dim][0]\n",
    "        lon_name = [dim for dim in original_data.coords if 'longitude' in dim][0]\n",
    "\n",
    "        # Regrid the data to the target grid without interpolating missing values\n",
    "        regridded_data = original_data.interp({lat_name: target_lat, lon_name: target_lon}, method='nearest')\n",
    "\n",
    "        # Convert the regridded data to a pandas DataFrame\n",
    "        regridded_dataframe = regridded_data.to_dataframe().reset_index()  # Reset index to have lon and lat as columns\n",
    "\n",
    "        # Rename columns to desired names\n",
    "        regridded_dataframe = regridded_dataframe.rename(columns={lat_name: \"Lat\", lon_name: \"Lon\", \"time\": \"Date\", \"precip\": \"rain\"})\n",
    "        \n",
    "        # Convert the date to the desired format YYYYMMDD\n",
    "        regridded_dataframe['Date'] = pd.to_datetime(regridded_dataframe['Date']).dt.strftime('%Y%m%d')\n",
    "\n",
    "        # Drop duplicate coordinate pairs (Lat, Lon, Date)\n",
    "        unique_coordinates = regridded_dataframe.drop_duplicates(subset=['Lat', 'Lon', 'Date'])\n",
    "\n",
    "        # Append to the combined DataFrame\n",
    "        combined_dataframe = pd.concat([combined_dataframe, unique_coordinates])\n",
    "\n",
    "# Drop duplicates in the combined DataFrame based on coordinates\n",
    "combined_dataframe = combined_dataframe.drop_duplicates(subset=['Lat', 'Lon', 'Date'])\n",
    "\n",
    "# Save the combined DataFrame with unique coordinates back to CSV\n",
    "csv_file_path = \"combined_unique_coordinates.csv\"\n",
    "combined_dataframe.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(\"Combined unique coordinates saved to:\", csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(csv_file_path)\n",
    "# List of column names to drop\n",
    "columns_to_drop = ['nv','lat_bounds','lon_bounds','time_bounds']  # Replace with your column names\n",
    "\n",
    "# Drop the specified columns\n",
    "data = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Date' column is in datetime format with the specified format 'YYYYMMDD'\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%Y%m%d')\n",
    "\n",
    "# Sort the DataFrame by 'Lat', 'Lon', and 'Date' columns\n",
    "data = data.sort_values(by=['Lat', 'Lon', 'Date'])\n",
    "\n",
    "data['Date'] = data['Date'].dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(data.columns)\n",
    "first_col = cols.pop(0)  # Remove the first column\n",
    "cols.insert(-1, first_col)  # Insert it at the second last position\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('rain.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Lat   Lon      Date  rain\n",
      "0  6.5  66.5  20030101   NaN\n",
      "1  6.5  66.5  20030102   NaN\n",
      "2  6.5  66.5  20030103   NaN\n",
      "3  6.5  66.5  20030104   NaN\n",
      "4  6.5  66.5  20030105   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "file_path = '/home/fgrslab/Saurabh_send/rain.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "# Print the first 5 rows of the DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
